{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Le classifier Naive Bayes \n",
    "\n",
    "* Le Naive Bayes est l’un des algorithmes de classification les plus simples à comprendre . Un des domaines d’application classique de ce modèle est la classification de textes en se basant uniquement sur la fréquence d’apparition des mots.\n",
    "\n",
    "* cette algorithme se repose  sur l’hypothèse simpliste (naïve) d’indépendance totale des variables, c’est un algorithme polyvalent dont on retrouve naturellement l’application dans de multiples secteurs d’activité, même quand l’hypothèse de base est violée . \n",
    "\n",
    "\n",
    "Le classifieur optimale de bayes est par : \n",
    "\n",
    "$$g(x) = \\argmax_{l \\in \\{1, \\dots, K \\} } \\mathbb{P}(Y=l|X=x)$$\n",
    "\n",
    "Pour pouvoir appliquer cette règle, il faut disposer des probabilité à posteriori $\\mathbb{P}(Y=l|X=x)$\n",
    "\n",
    "\n",
    "* Les approches basées sur un modèle consistent à apprendre la loi de $Y$ sachant\n",
    "$X$ pour en déduire ensuite la règle de classification $g$ on peut citer : \n",
    "\n",
    "1. analyse discriminante linéaire et quadratique, \n",
    "2. bayésien naïf\n",
    "3. régression logistique.\n",
    "4. $\\dots$\n",
    "\n",
    "Dans cette meme approche on peut scinder en deux : \n",
    "- *Une approche directe* : consiste à apprendre directement la loi de $Y$ sachant $X$. Par\n",
    "exemple en régression logistique \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import math \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import stats \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris( )\n",
    "X = data.data \n",
    "y = data.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaivesBayes: \n",
    "    def __init__(self):\n",
    "        self._pdf = np.vectorize(self._pdf)\n",
    "        self._exp = np.vectorize(self._pdf)\n",
    "\n",
    "\n",
    "    def fit(self, X, y): \n",
    "        n_samples, n_features = X.shape \n",
    "        self.n_classes = np.unique(y).shape[0]\n",
    "\n",
    "        data = np.concatenate([X, y.reshape(-1,1)], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        self.mean = np.zeros(shape=(self.n_classes, n_features))\n",
    "        self.var= np.zeros(shape=(self.n_classes, n_features)) \n",
    "        self.prior = np.zeros(shape=(self.n_classes))\n",
    "\n",
    "\n",
    "        for c in range(self.n_classes): \n",
    "            X_c = data[y==c][:, :-1]\n",
    "            self.mean[c] = X_c.mean(axis=0)\n",
    "            self.var[c]= X_c.var(axis=0)\n",
    "            prior_c = X_c.shape[0]/n_samples\n",
    "            self.prior[c]= prior_c\n",
    "\n",
    "\n",
    "    def predict(self,X, function): \n",
    "        predicted = [self._predict(x, function ) for x in X]\n",
    "        return np.array(predicted)\n",
    "\n",
    "        \n",
    "    \n",
    "    def _predict(self, obs, f=None):\n",
    "\n",
    "\n",
    "        L = []\n",
    "        for c  in range(self.n_classes):\n",
    "            res = f(obs, self.mean[c], self.prior[c]).prod() * self.prior[c]\n",
    "            L.append(res)\n",
    "        \n",
    "        L = np.array(L)\n",
    "\n",
    "        return  np.argmax(L) \n",
    "\n",
    "\n",
    "    \n",
    "    def _exp(self, x, lbd=12): \n",
    "\n",
    "        return lbd* math.exp(-lbd*x)\n",
    "        \n",
    "\n",
    "    def _pdf(self,x, mean, var):\n",
    "\n",
    "        numerator = math.exp((-(x-mean)**2)/(2*var))\n",
    "        denominator = math.sqrt(2* math.pi * (var))\n",
    "        return numerator / denominator\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaivesBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() got an unexpected keyword argument 'f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sq/462l7_3n27v2bh21r8_xxnkh0000gn/T/ipykernel_83048/1391797475.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: predict() got an unexpected keyword argument 'f'"
     ]
    }
   ],
   "source": [
    "model.fit(X, y)\n",
    "pred = model.predict(X, f = stats.norm.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9266666666666666"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, pred )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae728774eee256562aff2651c76309c3916f29437b55f618701e1f4834ebef1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env_tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
